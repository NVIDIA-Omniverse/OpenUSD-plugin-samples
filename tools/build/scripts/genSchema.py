# SPDX-FileCopyrightText: Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#

'''This module implements a wrapper around usdGenSchema for schema code / plugInfo generation
as well as generation of additional files needed to compile the plugin modules completely.'''

import argparse
import json
import os
import pathlib
import subprocess
import sys

from typing import List

# constant strings found in plugInfo.json
PLUGINS = "Plugins"
INFO = "Info"
TYPES = "Types"
BASES = "bases"
USD_TYPED = "UsdTyped"
API_SCHEMA_BASE = "UsdAPISchemaBase"
AUTO_GENERATED = "autoGenerated"

class TypeNode:
    """
    Represents a tree node for a type in a dependency tree.
    """

    def __init__(self, type_name: str, library_prefix: str):
        """
        Initializes a new instance.

        Args:
            type_name: A string representing the full
                       prefixed name of the type.
            library_prefix: A string denoting the library prefix
                            that may be attached to the type name.
        """
        self._type_name = type_name
        self._simple_name = type_name.replace(library_prefix, "")
        self._parent = None

    @property
    def type_name(self) -> str:
        """
        Retrieves the fully prefixed type name of the type.
        """
        return self._type_name

    @property
    def simple_name(self) -> str:
        """
        Retrieves the unprefixed name of the type.
        """
        return self._simple_name

    @property
    def parent(self) -> "TypeNode":
        """
        Retrieves the parent of the type.  This will be None
        if the type does not exist in the schema being processed.
        """
        return self._parent

    @parent.setter
    def parent(self, parent: "TypeNode"):
        """
        Sets the parent node of this node.
        """
        self._parent = parent

def generate_module_wrap_statements(plug_info_path: pathlib.Path, library_prefix: str) -> str:
    """
    Generates the sequence of TF_WRAP statements required to initialize
    the python module from the generated schema code.

    Args:
        plug_info_path: The path to the generated plugInfo.json file.
        library_prefix: The prefix for all generated schema classes in the module.

    Returns:
        A string defining the set of TF_WRAP statements required to integrate into the
        wrapped module.
    """
    if not os.path.exists(plug_info_path):
        raise RuntimeError("Unable to locate plugInfo.json file for TF_WRAP module generation!")
    
    def process_type(type_node: TypeNode, processed_types: List[str]) -> List[str]:
        """
        Processes a given type from the schema and returns the TF_WRAP statements
        needed for the module.cpp file.
        """
        tf_wrap_statements = []
        if type_node.parent is not None:
            wrap_statements.extend(process_type(type_node.parent, processed_types))

        # if it didn't get processed yet, process it now
        if type_node.type_name not in processed_types:
            tf_wrap_statements.append("TF_WRAP(" + type_node.type_name + ");")
            processed_types.append(type_node.type_name)

        return tf_wrap_statements

    type_to_base_map = {}
    type_nodes = {}
    plug_info_content = ""
    with open(plug_info_path, "r") as pif:
        # the plugInfo.json file has unsanitized json content
        # because the generator adds python style comments to it
        # so we have to strip those first
        for plug_info_line in pif:
            if not plug_info_line.startswith("#"):
                plug_info_content += plug_info_line

    # load the json content
    plug_info_content = json.loads(plug_info_content)

    # there should only be one plugin in the generated content
    if PLUGINS not in plug_info_content:
        raise RuntimeError("'Plugins' key not found in generated plugInfo.json!")

    plugins = plug_info_content[PLUGINS]
    for plugin in plugins:
        if INFO not in plugin:
            raise RuntimeError("No 'Info' key detected in generated plugInfo.json!")

        plugin_info = plugin[INFO]
        if TYPES not in plugin_info:
            raise RuntimeError("No 'Types' key detected in generated plugInfo.json!")

        plugin_types = plugin_info[TYPES]
        for type_key in plugin_types:
            # only care about it if it was auto-generated
            # because there might be other types in the library that
            # aren't generated schema types
            if AUTO_GENERATED not in plugin_types[type_key] or \
                not plugin_types[type_key][AUTO_GENERATED]:
                continue

            # there has to be a base type
            if BASES not in plugin_types[type_key]:
                raise RuntimeError(
                    f"No 'Bases' key detected for type '{type_key}' in pluginInfo.json!"
                )

            base_types = plugin_types[type_key][BASES]

            # in all cases, there should only be one type in the generated content
            # since schema classes can only derive from a single other class
            base_type = base_types[0]

            type_node = TypeNode(type_key, library_prefix)
            type_to_base_map.update({type_key: base_type})
            type_nodes.update({type_key: type_node})

        # now we have a list of all types in the schema
        # we need to go through and parent them properly
        for key, node in type_nodes.items():
            # the type_to_base_map stores the string name of the parent
            # we have to convert this to a type node reference
            # for the type node object
            base_type = type_to_base_map[key]
            if base_type in type_nodes:
                # base type is not a known USD type and exists
                # within the current schema, so set the parent appropriately
                type_node.parent = type_nodes[base_type]

    # now we have a dependency tree, we can process them
    processed = []
    wrap_statements = []
    for _, node in type_nodes.items():
        wrap_statements.extend(process_type(node, processed))

    # add the wrap statement for the tokens
    wrap_statements.append("TF_WRAP(" + library_prefix + "Tokens);")

    return "\"" + "\n     ".join(wrap_statements) + "\""

if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "schema_file",
        help="The schema file used to generate OpenUSD artifacts with"
    )

    parser.add_argument(
        "--generate-dir",
        dest="generate_dir",
        required=True,
        help="The directory in which to generate the OpenUSD artifacts"
    )

    parser.add_argument(
        "--usd-root",
        dest="usd_root",
        required=True,
        help="The root directory of the OpenUSD installation to use to generate the OpenUSD artifacts"
    )

    parser.add_argument(
        "--python-root",
        dest="python_root",
        required=True,
        help="The root directory of the Python installation to use to generate the OpenUSD artifacts"
    )

    args = parser.parse_args()

    print("Executing schema generation...")
    print(f"  -- OpenUSD Root: {args.usd_root}")
    print(f"  -- Python Root: {args.python_root}")
    print(f"  -- Schema File: {args.schema_file}")
    print(f"  -- Target Location: {args.generate_dir}")
    print(f"  -- Python Environment: {sys.executable}")

    if not os.path.exists(args.generate_dir):
        os.mkdir(args.generate_dir)

    usd_gen_schema_path = os.path.join(args.usd_root, "bin", "usdGenSchema")
    process_env = os.environ.copy()
    process_env["PYTHONPATH"] = os.path.join(args.usd_root, "lib", "python")
    process_env["PATH"] = os.path.join(args.usd_root, "lib") + os.pathsep + process_env["PATH"]
    process_env["PATH"] = os.path.join(args.usd_root, "bin") + os.pathsep + process_env["PATH"]
    process_env["PATH"] = os.path.join(args.python_root) + os.pathsep + process_env["PATH"]
    process_args = [
        sys.executable,
        usd_gen_schema_path,
        args.schema_file,
        args.generate_dir
    ]

    try:
        process = subprocess.run(process_args, check=True, env=process_env, capture_output=True)
    except subprocess.CalledProcessError as e:
        print(e.output.decode("utf-8"))
        raise e

    # parse the output to find out what files were written
    public_header_files = []
    source_files = []
    resource_files = []
    python_source_files = []
    python_files = []
    plug_info_file = None
    output = process.stdout.decode()
    lines = output.split("\n")
    for line in lines:
        line = line.strip()
        path = None
        if line.startswith("wrote"):
            line = line.replace("wrote ", "")
            path = pathlib.Path(line)
        elif line.startswith("unchanged"):
            line = line.replace("unchanged ", "")
            path = pathlib.Path(line)

        if path is not None:
            if path.name.endswith(".h"):
                public_header_files.append(path.name)
            elif path.name.endswith(".cpp") and not path.name.startswith("wrap"):
                source_files.append(path.name)
            elif path.name.endswith(".cpp") and path.name.startswith("wrap"):
                python_source_files.append(path.name)
            else:
                if path.name == "plugInfo.json":
                    plug_info_file = path

                resource_files.append(path.name)

    # heuristically determine the library prefix
    schema_library_prefix = None
    schema_library_name = None
    is_codeless = "false"
    with open(args.schema_file, "r") as sf:
        for line in sf:
            if "string libraryName" in line:
                equal_index = line.find("=")
                if equal_index != -1:
                    schema_library_name = line[equal_index + 1:].replace('"', '').strip()
            if "string libraryPrefix" in line:
                equal_index = line.find("=")
                if equal_index != -1:
                    schema_library_prefix = line[equal_index + 1:].replace('"', '').strip()
            if "bool skipCodeGeneration" in line:
                equal_index = line.find("=")
                if equal_index != -1:
                    is_codeless_str = line[equal_index + 1:].strip()
                    is_codeless = is_codeless_str.lower() == "true"

    if schema_library_prefix is None:
        if schema_library_name is None:
            raise RuntimeError(f"Unable to determine schema library prefix from {args.schema_file}!")

        schema_library_prefix = schema_library_name[0].upper() + schema_library_name[1:]

    # now generate the information required for the module.cpp file
    # this is a little complicated, because we have to find all TF_WRAP
    # statements that are generated and sort them in base class -> derived class order
    module_wrap_statements = generate_module_wrap_statements(plug_info_file, schema_library_prefix)

    # output a cmake file that can be included in the main template
    output_file = os.path.join(args.generate_dir, "gen_schema_output.cmake")
    with open(output_file, "w") as f:
        f.write(f"set(PXR_GENERATED_PUBLIC_HEADERS {' '.join(public_header_files)})\n")
        f.write(f"set(PXR_GENERATED_CPP_FILES {' '.join(source_files)})\n")
        f.write(f"set(PXR_GENERATED_RESOURCE_FILES {' '.join(resource_files)})\n")
        f.write(f"set(PXR_GENERATED_PYTHON_CPP_FILES {' '.join(python_source_files)})\n")
        f.write(f"set(PXR_GENERATED_PYTHON_FILES {' '.join(python_files)})\n")
        f.write(f"set(PXR_PYTHON_PLUGIN_WRAP_CLASSES {module_wrap_statements})\n")
        f.write(f"set(PXR_SCHEMA_IS_CODELESS {str(is_codeless).upper()})")
